{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN implementation using python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg4p2ylc5QPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "306b35c5-c02b-4741-c53b-cab923463062",
        "id": "N8nGVPEC6XBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#initilizing CNN\n",
        "classifier=Sequential()\n",
        "#Step1 : Convolution\n",
        "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
        "#Step2 :Pooling\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#Step3 :Flattening\n",
        "classifier.add(Flatten())\n",
        "#Step4 : Full connection step(Here output is binary that is why sigmoid activation function is used )\n",
        "classifier.add(Dense(output_dim =128,activation='relu'))\n",
        "classifier.add(Dense(output_dim =1,activation='sigmoid'))\n",
        "classifier.compile(optimizer='adam' , loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22JOoZjA5_U5",
        "colab_type": "code",
        "outputId": "1b514753-10a9-47f4-b5c3-cf91ec77cbdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "tf.__version__\n",
        "\n",
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "# Part 2 - Building the CNN\n",
        "\n",
        "# Initialising the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Step 4 - Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Step 5 - Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Part 3 - Training the CNN\n",
        "\n",
        "# Compiling the CNN\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Training the CNN on the Training set and evaluating it on the Test set\n",
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 39)\n",
        "\n",
        "# Part 4 - Making a single prediction\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "'''we’re using 3 channels because our images are color and therefore need to transform this image into a 3D array. To do this we use \n",
        "the img_to_array function from the imagemodule.'''\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "''' expand_dims method from numpy to add this new dimension. It takes the first parameter as the test image we are expanding, and the second \n",
        "parameter is the position of the dimension we are adding. The predict method expects this new dimension in the first position, which\n",
        " corresponds to axis 0.'''\n",
        "result = cnn.predict(test_image)\n",
        "'''Now we use the predict method to predict which class the image belongs to.'''\n",
        "training_set.class_indices\n",
        "''' we don’t know which value represents which class. To find out, we use the class_indices attribute of the training set.'''\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "print(prediction)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1035 images belonging to 3 classes.\n",
            "Found 1029 images belonging to 3 classes.\n",
            "Epoch 1/39\n",
            "33/33 [==============================] - 11s 331ms/step - loss: -860.3592 - accuracy: 0.4077 - val_loss: -2943.4395 - val_accuracy: 0.6395\n",
            "Epoch 2/39\n",
            "33/33 [==============================] - 11s 328ms/step - loss: -34068.7070 - accuracy: 0.4126 - val_loss: -65275.2656 - val_accuracy: 0.6395\n",
            "Epoch 3/39\n",
            "33/33 [==============================] - 11s 327ms/step - loss: -334467.3438 - accuracy: 0.4126 - val_loss: -463300.3750 - val_accuracy: 0.6395\n",
            "Epoch 4/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -1637239.0000 - accuracy: 0.4126 - val_loss: -1900040.3750 - val_accuracy: 0.6395\n",
            "Epoch 5/39\n",
            "33/33 [==============================] - 11s 328ms/step - loss: -5571023.5000 - accuracy: 0.4126 - val_loss: -5639984.5000 - val_accuracy: 0.6395\n",
            "Epoch 6/39\n",
            "33/33 [==============================] - 11s 327ms/step - loss: -14697132.0000 - accuracy: 0.4126 - val_loss: -13566158.0000 - val_accuracy: 0.6395\n",
            "Epoch 7/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -32513282.0000 - accuracy: 0.4126 - val_loss: -28086220.0000 - val_accuracy: 0.6395\n",
            "Epoch 8/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -62695288.0000 - accuracy: 0.4126 - val_loss: -52171880.0000 - val_accuracy: 0.6395\n",
            "Epoch 9/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -111186720.0000 - accuracy: 0.4126 - val_loss: -89032320.0000 - val_accuracy: 0.6395\n",
            "Epoch 10/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -184664160.0000 - accuracy: 0.4126 - val_loss: -142979056.0000 - val_accuracy: 0.6395\n",
            "Epoch 11/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -287021856.0000 - accuracy: 0.4126 - val_loss: -217789024.0000 - val_accuracy: 0.6395\n",
            "Epoch 12/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -430130272.0000 - accuracy: 0.4126 - val_loss: -318815104.0000 - val_accuracy: 0.6395\n",
            "Epoch 13/39\n",
            "33/33 [==============================] - 11s 327ms/step - loss: -617440320.0000 - accuracy: 0.4126 - val_loss: -452131392.0000 - val_accuracy: 0.6395\n",
            "Epoch 14/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -858238208.0000 - accuracy: 0.4126 - val_loss: -620233344.0000 - val_accuracy: 0.6395\n",
            "Epoch 15/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -1168656768.0000 - accuracy: 0.4126 - val_loss: -829422528.0000 - val_accuracy: 0.6395\n",
            "Epoch 16/39\n",
            "33/33 [==============================] - 11s 333ms/step - loss: -1550827136.0000 - accuracy: 0.4126 - val_loss: -1093743744.0000 - val_accuracy: 0.6395\n",
            "Epoch 17/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -2013441152.0000 - accuracy: 0.4126 - val_loss: -1412685440.0000 - val_accuracy: 0.6395\n",
            "Epoch 18/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -2568788992.0000 - accuracy: 0.4126 - val_loss: -1787165568.0000 - val_accuracy: 0.6395\n",
            "Epoch 19/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -3243483136.0000 - accuracy: 0.4126 - val_loss: -2232509696.0000 - val_accuracy: 0.6395\n",
            "Epoch 20/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -4009929728.0000 - accuracy: 0.4126 - val_loss: -2747779072.0000 - val_accuracy: 0.6395\n",
            "Epoch 21/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -4921081344.0000 - accuracy: 0.4126 - val_loss: -3357127168.0000 - val_accuracy: 0.6395\n",
            "Epoch 22/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -5969100288.0000 - accuracy: 0.4126 - val_loss: -4064489728.0000 - val_accuracy: 0.6395\n",
            "Epoch 23/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -7173884416.0000 - accuracy: 0.4126 - val_loss: -4844321280.0000 - val_accuracy: 0.6395\n",
            "Epoch 24/39\n",
            "33/33 [==============================] - 11s 323ms/step - loss: -8520190464.0000 - accuracy: 0.4126 - val_loss: -5748382720.0000 - val_accuracy: 0.6395\n",
            "Epoch 25/39\n",
            "33/33 [==============================] - 11s 322ms/step - loss: -10050839552.0000 - accuracy: 0.4126 - val_loss: -6749804544.0000 - val_accuracy: 0.6395\n",
            "Epoch 26/39\n",
            "33/33 [==============================] - 11s 328ms/step - loss: -11793005568.0000 - accuracy: 0.4126 - val_loss: -7886908416.0000 - val_accuracy: 0.6395\n",
            "Epoch 27/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -13800554496.0000 - accuracy: 0.4126 - val_loss: -9155113984.0000 - val_accuracy: 0.6395\n",
            "Epoch 28/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -15890954240.0000 - accuracy: 0.4126 - val_loss: -10553841664.0000 - val_accuracy: 0.6395\n",
            "Epoch 29/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -18270287872.0000 - accuracy: 0.4126 - val_loss: -12090215424.0000 - val_accuracy: 0.6395\n",
            "Epoch 30/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -20946704384.0000 - accuracy: 0.4126 - val_loss: -13811986432.0000 - val_accuracy: 0.6395\n",
            "Epoch 31/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -23788423168.0000 - accuracy: 0.4126 - val_loss: -15679574016.0000 - val_accuracy: 0.6395\n",
            "Epoch 32/39\n",
            "33/33 [==============================] - 11s 324ms/step - loss: -26853812224.0000 - accuracy: 0.4126 - val_loss: -17689950208.0000 - val_accuracy: 0.6395\n",
            "Epoch 33/39\n",
            "33/33 [==============================] - 11s 331ms/step - loss: -30360489984.0000 - accuracy: 0.4126 - val_loss: -19906568192.0000 - val_accuracy: 0.6395\n",
            "Epoch 34/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -34056630272.0000 - accuracy: 0.4126 - val_loss: -22322657280.0000 - val_accuracy: 0.6395\n",
            "Epoch 35/39\n",
            "33/33 [==============================] - 11s 325ms/step - loss: -38100832256.0000 - accuracy: 0.4126 - val_loss: -24941291520.0000 - val_accuracy: 0.6395\n",
            "Epoch 36/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -42605322240.0000 - accuracy: 0.4126 - val_loss: -27715696640.0000 - val_accuracy: 0.6395\n",
            "Epoch 37/39\n",
            "33/33 [==============================] - 11s 326ms/step - loss: -47377051648.0000 - accuracy: 0.4126 - val_loss: -30731667456.0000 - val_accuracy: 0.6395\n",
            "Epoch 38/39\n",
            "33/33 [==============================] - 11s 327ms/step - loss: -52259676160.0000 - accuracy: 0.4126 - val_loss: -33969625088.0000 - val_accuracy: 0.6395\n",
            "Epoch 39/39\n",
            "33/33 [==============================] - 11s 327ms/step - loss: -57759670272.0000 - accuracy: 0.4126 - val_loss: -37446819840.0000 - val_accuracy: 0.6395\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-KsgCbqWd6O",
        "colab_type": "code",
        "outputId": "37334e94-d47c-4a61-aeba-c71351b923ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_set.class_indices\n",
        "#Assuming you had done this classification for cats and dogs you would get 2 categories\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.ipynb_checkpoints': 0, 'cats': 1, 'dogs': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}